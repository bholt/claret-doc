# Leveraging Data Types

At the application level, actions like `PlaceBid` may obviously commute with one another, but once these actions have been broken down into individual `put` and `get` operations, that knowledge is lost. The datastore no longer has any way to see that which reorderings are allowable, so adding multiple items to a `Set`, for instance, just looks like a series of writes with some implicit order. We need some way to communicate these higher-level properties about the application to the storage and execution system.

As was alluded to earlier, data types hold the key. Specifically, the notion of *abstract data types* (ADTs) logically decouples the abstract behavior, where operations may be commutative, associative, monotonic, etc, from the low-level implementation that instantiates that behavior with lower-level reads and writes.

Reasoning at the level of ADTs is good for programmers and datastores alike. Higher-level ADT operations expose more flexibility to the datastore, such as chances for reordering or cheaper ways of executing them. At the same time, programmers enjoy re-using existing data structures and have control over which data types they use to build their applications, including designing their own. ADTs can range from simple primitive data types like `Set`, to fully application-specific types, like an `Auction` data type with commutative `PlaceBid` operations.

General transactions allow ADT operations to be composed to perform more complex actions. The level of complexity of the data types is up to the programmer and can affect performance. Consider three implementations shown in [#placebid]. The first, using generic records, is correct but doesn't expose commutativity. The second and third ones express commutativity, but the third uses a custom `Auction` data type, while the second uses a standard Redis-style `SortedSet` ADT, whose `add` operations naturally commute. In this case, these last two should have roughly the same `PlaceBid` performance, but in other cases a single built-in data type is not sufficient, but may still express significant concurrency.

~ Listing { #placebid caption="Three different pseudocode implementations of `PlaceBid`, showing various levels of ADT complexity. [todo: what's a good standard datastore interface to use to write these kinds of operations? maybe look at Redis bindings?]" }
```python
# Generic records: not expressing commutativity
def transactionPlaceBid_A(item, bidder, price):
  UserBids(bidder+":"+item).put(item)
  if price > MaxBid(item).get():
    MaxBid(item).put(price)
    MaxBidder(item).put(bidder)

# SortedSet: expresses commutativity, generally reusable
def transactionPlaceBid_B(item, bidder, price):
  ItemBids(item).add((price, bidder)) # SortedSet
  UserBids(bidder).add(item)        # Set

# Custom Auction ADT: commutative, but app-specific
def transactionPlaceBid_C(item, bidder, price):
  Auction(item).placeBid(price, bidder)
```
~

Considering that we know the abstract semantics of operations on data types, how can we leverage them specifically in datastores? The next few sections will describe some existing techniques which can be applied to ADT-aware datastores.

## Transaction Boosting

To ensure serializability, executing transactions requires some form of concurrency control. A common approach is two-phase-locking (2PL), where a transaction must acquire locks on all the records it is accessing before performing any irreversible changes. Typically these locks are reader/writer locks, so multiple read operations can be executed concurrently in different transactions. This means that transactions need not abort if they are reading a record already being read by other transactions, but writes cause transactions to abort. This behavior is the same with optimistic concurrency control.

*Abstract locks* [@Ni:07] generalize the notion of reader/writer locks to any operations which can logically run concurrently on the same record. Using an abstract lock for an ADT, the concurrency control mechanism can allow operations that commute to run concurrently. There is a similar way to represent this behavior in optimistic concurrency control schemes, too.

If we can express the *commutativity* of our ADT operations to the concurrency control system via abstract locks, then it could avoid aborting many more transactions, especially on highly contended records. This idea of raising the level of reasoning to higher-level ADT operations is known as *transaction boosting* [@Herlihy:PPoPP08] in the transactional memory community.

## Operation Combining

Another useful property of some ADT operations is *associativity*. If we think of *commutativity*, which we used in boosting above, as allowing operations to be executed in a different order on a given record, then *associativity* allows us to merge some of those operations together *before* applying them to the record. 

## Phasing

Sometimes the order that operations happen to arrive causes problems when applying the two former optimizations. In particular, leveraging commutativity only really works if many of the operations that commute with each other arrive together. If they are interleaved in time with operations they do not commute with, then all of that cleverness is for naught.

Borrowing the term from recent work on *phase reconciliation* [@Narula:OSDI14], *phasing* is the idea of enforcing order on operations that are otherwise unordered, in order to execute them more efficiently.
