# Leveraging data types {#sec-leveraging}

<!--
~ Fig { #fig-adt-bid caption="Claret programming model example showing the ADT for a scored set and how it can be used to implement the Bid transaction from [#fig-levels]." }
![Example ADT version of Bid transaction](fig/adt-bid.pdf){.onecol}
~
-->

<!--
- adts hide their implementation, allow reasoning about abstract behavior
- if abstract view allows reordering, then concurrency control can take advantage of that
- use adts to express application-level properties
 -->

<!-- At the application level, actions like `Bid` may obviously commute with one another, but once these actions have been broken down into individual `put` and `get` operations, that knowledge is lost. The datastore no longer has any way to see that which reorderings are allowable, so adding multiple items to a `Set`, for instance, just looks like a series of writes with some implicit order. We need some way to communicate these higher-level properties about the application to the storage and execution system. -->

<!-- Abstract data types ... because they allow reasoning about the abstract behavior -->
<!-- are a natural and succinct way to implement applications.  -->

<!-- As was alluded to earlier, data types hold the key. Specifically, the notion of  -->

In Claret, programmers express application-level semantics through ADTs. We know that the `Bid` transactions in [#fig-levels] should commute somehow, and we need to be able to determine the current high bid.
A `topk` set meets our needs: it associates a score with each item, but only tracks the ones with the top scores. Because `topk.add` operations commute, `Bid` transactions no longer conflict. Applications express their desired semantics by choosing the most specific ADT for their needs, either by choosing from the built-in ADTs ([#tab-adt-list]) or implementing their own (see [#sec-expressing]).

Abstract data types decouple their abstract behavior from their low-level concrete implementation.
Abstract operations can have properties such as commutativity, associativity, or monotonicity, which define how they can be reordered or executed concurrently, while the concrete implementation takes care of performing the necessary synchronization.

Knowledge of these properties can be used by the datastore in many ways to improve performance. First, we will show how commutativity can be used in the concurrency control system to avoid false conflicts (*boosting*) and ordering constraints (*phasing*). Then we will give an example of how associativity can be applied to reduce the load on the datastore (*combining*).

## Transaction boosting {#sec-boosting}

To ensure strong isolation, all transactional storage systems implement some form of concurrency control. A common approach is strict two-phase-locking (S2PL), where a transaction acquires locks on all records in the execution phase before performing any irreversible changes. Typically these are reader/writer locks, so multiple read operations can execute concurrently in different transactions. This means that transactions need not block if they are reading a record already being read by other transactions, but writes cause other transactions to block.

*Abstract locks* [@Ni:07] generalize the notion of reader/writer locks to any operations which can logically run concurrently on the same record. With an abstract lock for an ADT, the concurrency control system can allow any operations that commute to hold the lock at the same time. For `zset`, `add` operations can all hold the lock at the same time, but reading operations such as `size` must wait. The same idea can be applied to optimistic concurrency control: operations only cause conflicts if the abstract lock doesn't allow them to execute concurrently with other outstanding operations.

Using abstract locks to improve concurrency in transactions is known as *transaction boosting* [@Herlihy:PPoPP08] in the transactional memory community. However, this technique can be even more valuable to distributed transactions because their performance depends on how long locks are held. Waiting for one lock causes a cascade of waiting as others wait on the locks the blocked transaction holds. Every operation that can share an abstract lock reduces the time the rest of its locks are held for, which can have a big impact on performance.
In OCC-based systems, boosting reduces the abort rate because fewer operations conflict with one another.

[todo: bring this more to forefront] Boosting is especially important for highly contended records. In the case of auctions, when a particularly hot auction is near closing time, it can expect to receive a huge number of bids. If all of the bids conflict with each other and serialize, it may cause some of them to not complete in time. However, if the bids are represented using a `zset`, then they naturally commute, the transactions can execute concurrently, and everyone gets to place their bids.

## Phasing {#sec-phasing}

Sometimes the order that operations happen to arrive causes problems with abstract locks. In particular, they only help if the operations that commute with each other arrive together. If they are interleaved in time with operations they do not commute with, then all of that cleverness is for naught. Borrowing the term from recent work on *phase reconciliation* [@Narula:OSDI14], *phasing* is the idea of reordering operations so that commuting operations execute together.

To implement phasing, each ADT defines a *phaser* which is responsible for grouping operations into *phases* which can execute together. The interface will be described in more detail in [#sec-phaser]. Each record (or rather, the lock on the record), has its own phaser which keeps track of which mode is currently executing and keeps queues of operations in other modes waiting to acquire the lock. The phaser then cycles through these modes, switching to the next when all the operations in a phase have committed.

[todo: very wordy] Phasing also helps ensure fairness and prevent starvation. When operations try to acquire a lock, usually they either succeed and get the lock or are denied and must retry. When they retry, they may find that the lock is again held by someone else, possibly someone who started later, but got lucky and arrived at the right time. Alternatively, a record may receive a steady stream of read-only operations and some mutating operations. If there is always at least one outstanding read, then the read lock will never be released and the writes may starve. Instead, phases are capped at a maximum duration as long as operations in other modes are queued up.

Reader/writer locks can also benefit from phasing; in that case, there are just two modes, reading and writing, though writing, of course, only allows one operation at a time.

Due to phasing, the latency of some operations may increase as they are forced to wait for their phase to come. However, reducing conflicts often reduces the latency of transactions overall.

## Combining {#sec-combining}

Another useful property on operations is *associativity*. If we think of *commutativity*, used in boosting above, as allowing operations to be executed in a different order on a given record, then *associativity* allows us to merge some of those operations together *before* applying them to the record. This technique, known as *combining* [@flatCombining; @yew:combining-trees; @funnels] can drastically reduce contention on shared data structures and improve performance in situations where applying the combined operation is cheaper than applying the operations one-by-one. In distributed settings, combining can be even more useful as it effectively distributes synchronization for a single data structure over multiple hosts [@flat-combining-pgas13].

For distributed datastores where the network is typically the bottleneck, combining can help reduce the load on the server. If many clients all wish to perform operations on one record, each of them must send a message to acquire the lock. Even if they commute and so can hold the lock concurrently, the shard handling the requests can get overloaded. In our model, however, "clients" are actually frontend servers handling many different end-user requests. With combining enabled, Claret keeps track of all the locks currently held by transactions on one frontend server. Whenever a client performs an operation that can be combined with one of the outstanding ones, it combines them and the combined operation no longer needs to talk to the server to acquire the lock itself.

For correctness, transactions sharing combined operations must all commit together. This also means that they must not conflict on any of their other locks, otherwise they would deadlock, and this applies transitively through all combined operations. Claret handles this by merging the locks sets of the two transactions whenever operations are combined and aborting a transaction and removing it from the set if it later performs an operation that conflicts with the others.

With all the overhead of tracking outstanding locks and merging transaction sets, it seems like this might be more work than it is worth, and it likely is in some cases. However, these frontend servers can often afford to spend this effort to try combining because they are easy to replicate to handle additional load, whereas the datastore shards they are saving work for cannot. [todo: weird wording]
