<!--
  Outline:
    - where does contention come from?
      - power-law distributions
      - live events focus things in time
    - why do we care?
      - most of the time, things are fine
      - but high-contention times are probably also your most important
    - modeling real workloads
      - twitter: power-law degree (followers), retweet popular tweets you see
      - auction: power-law num of bids per item, more bids near end of auction
-->

# Real world contention

Some applications scale out well — more data provides more "room" to spread out and go without interaction. However, systems interacting with the real world often exhibit common patterns which are challenging: skewed access patterns, such as those resulting from low-diameter networks ("small-world" property of social networks), and activity spikes resulting from realtime events (tweets following a World Cup goal). When combined, network and timing effects can amplify small signals into massive bursts of activity, such as when a meme "goes viral".

## Power laws everywhere

Properties of real-world systems often follow power-law distributions due to a variety of common effects. The connectivity of social networks are a well-known example, where a small number of nodes (people) account for a large fraction of the connections, while most people have relatively few connections. These power laws can play off of each other, leading to other interesting properties, such as low diameter or *small-world* networks (colloquially, "six degrees of separation"). Other network effects serve to amplify small signals into massive amounts of activity, such as occurs when a topic "goes viral".

If not taken into account in the design, these properties can easily bring systems crashing down, or slowing to a standstill. Load spikes, when traffic jumps significantly higher than the norm, causes increased conflicts. More challenging, however, is the skewed popularity of keys or records — such *hot spots* end up funneling massive numbers of concurrent clients down to a small number of nodes which have the necessary data or are responsible for synchronization.

To discuss this more concretely, we will use an eBay-like online auction service, based on the well-known RUBiS benchmark [@Amza:02], as our running example. At its core, this service allows users to put items up for auction, browse items by region and category, and place bids on open auctions. The original specification of the benchmark describes a workload with a mix of bidding and browsing (and opening and closing auctions), and specifies an average number of bids per auction. However, RUBiS never specified a *distribution* of bids per item, nor for any of the entities in the benchmark, which can have a massive impact on performance.

~ Fig { #plot-bids-per-item caption="Log-log plot showing the number of bids per item in this auction simulation matches the power law distribution observed empirically." }
![bids per item power-law plot](plots/bid-dist.pdf){.onecol}
~

~ Fig { #plot-bid-time caption="Frequency of bids with respect to the auction window (auction opens at 0%, closes at 100%) for all items in a , indicating higher rates of bids as closing times near." }
![bid time plot](plots/bid-time.pdf)
~

Surveys of real-world auction sites [@Menasce:07;@Akula:04] can give us an idea of what these distributions should be. Akula and Menascé [@Akula:04] observed that not only do the number of bids per item roughly follow Zipf's Law (a *zipfian* distribution), so too do the number of bids per bidder, amount of revenue per seller, number of auction wins per bidder, and others. Furthermore, they observed that the majority of bids arrive near the end of the auction window as bidders attempt to out-bid one another, as shown in [#bid-dist]. [todo: find more measurement studies?] The number and frequency of bids for even single auction exceeds the capacity of a single machine. The ability to get bids in will be directly related to revenue of an auction site, as well as being responsible for user satisfaction, and this case, at least, is definitely not suitable for weaker consistency. Therefore, we need to find ways to satisfy performance needs without sacrificing strong consistency.

## Commutativity is common

Luckily, high-contention situations often share other, more useful, properties like commutativity and associativity. At a high level, it should be clear that bids placed on an item can be reordered with one another, provided that the correct maximum bid can still be tracked. Whenever a browse action observes the maximum bid or the auction closes, that must impose an ordering that bids cannot move beyond, but bids themselves can be reordered with each other. That is to say, bids *commute* with one another because conceptually, there is an *ordered set* of bids and ultimately we only care about the maximum value.

Modeling the power law properties described above, we generated a new RUBiS workload that is more indicative of real-world auctions. With this simulation, we can measure all of the conflicts that would occur between auction transactions under this workload when executed naively. Using techniques which will be described in the rest of this paper, we found which transactions actually commute with one another, and measured those as well. [#auction-conflicts] shows the results of this simulation for four of the most important transaction types. We can see that the bid-to-bid conflicts are the most significant, but commutativity completely eliminates them.

~ Fig { #auction-conflicts caption="Conflicts between 4 important auction transactions, without/with commutativity. The majority of conflicts (between bids) are completely eliminated by recognizing that they commute with one another. [todo: collect numbers for *potential/theoretical* conflicts, not actual]" }
<!-- ![Auction conflicts](fig/rubis-conflicts.pdf){.onecol} -->
|         | Open        | Bid             |  Browse    |  Close     |
|:--------+:-----------:|:---------------:|:----------:|:----------:|
| Open    | 146 / 0     |                 |            |            |
| Bid     | 0 / 0       | **235,000 / 0** |            |            |
| Browse  | 532 / 787   | 566 / 821       | 0 / 0      |            |
| Close   | 0 / 0       | 650 / 431       | 278 / 388  | 446 / 230  |
{ th-font-weight=normal font-family=HelveticaNeue }
~

The rest of this paper will tackle how we can use this information in the datastore to execute fast even under high contention and how programmers can express these properties to the datastore for their applications.
