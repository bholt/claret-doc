# Evaluation

To understand the potential performance impact of the optimizations enabled by ADTs, we built a prototype in-memory ADT-store. This custom implementation, written in C++, uses UDP to transmit messages between clients (representing frontend servers) and servers. Records are kept in their in-memory representations; compared with most traditional key-value stores (with the exception of Redis) this saves time as serializing and deserializing is only performed on values being sent in or returned from operations. [todo: reliable transport, very little packet loss? or just don't say UDP]

As discussed before, Claret uses a standard two-phase locking scheme to isolate transactions.
The baseline uses reader/writer locks which allow any number of read-only operations in parallel, but requires an exclusive lock for operations that modify the record. When boosting is enabled, these are replaced with abstract locks, which allow any operations that commute with one another to hold the lock at the same time. By default, operations retry whenever they fail to acquire a lock; with phasing, replies are sent whenever the lock is finally acquired, so retries are only used to resolve deadlocks or lost packets.

This prototype does not ensure fault-tolerance or durability. These could be implemented by replicating shards or logging operations to persistent storage. Mirroring operations to other replicas or waiting for filesystem syncs would be expected to increase the amount of time spent holding locks, which should be expected to exaggerate the results obtained in our experiments since the longer locks are held, the more concurrency is required. [todo: need a clearer explanation here. i think you are saying that support for durability and fault-tolerance will make your results better, but it is unclear.]

[todo: say what questions you want to answer with the evaluation.]


All the following experiments are run on our own cluster. Each node has dual 6-core 2.66 GHz Intel Xeon X5650 processors with 24 GB of memory, connected with a 40Gb Mellanox ConnectX-2 InfiniBand network. Unless otherwise noted, experiments are run with 4 single-threaded shards running on 4 different nodes, with 4 clients running on other nodes with variable numbers of threads. Average round-trip times between nodes for UDP packets are 150 µs.


## Raw Operation Mix

To begin with, we explore the effects of each of the optimizations with transactions performing a random mix of operations similar to YCSB [@YCSB]. Each transaction executes a fixed number of operations, randomly selecting either a read operation (set `size`), or a commutative write operation (set `insert`), and keys selected randomly with a zipfian distribution from a pool of 10,000 keys. By varying the percentage of writes and the zipfian parameter, we can control the amount of contention in this artificial workload and quantify the impact of each optimization on performance. The zipfian parameter determines the shape of the distribution; a value of 1 corresponds to Zipf's Law, lower values are shallower and more uniform, higher values more extremely skewed.

~ Fig { #plot-rawmix caption="Performance of raw mix workload (50% read, zipf: 0.6) with increasing number of clients, plotted as throughput versus latency. Phasing helps keep latency low even for r/w locks, but boosting (abstract locks) unlocks much more concurrency, resulting in a much higher peak throughput, 67% of the non-transactional peak which doesn't have strong consistency guarantees." }
![Raw mix throughput versus latency](plots/rawmix-tput-vs-lat.pdf){ .onecol }
~

~ Fig { #plot-rawmix-retries caption="Transaction retries for Rawmix workload with 384 clients. Throughput is largely determined by retries. Phasing, boosting, and combining all reduce retries in different ways." }
![Raw mix throughput versus latency](plots/rawmix-retries.pdf){ .onecol }
~


First, we start with a 50% read, 50% write workload and a modest zipfian parameter of 0.6, and vary the number of clients. [#plot-rawmix] shows a throughput versus latency plot with lines for each of the optimization conditions as we vary the number of clients (from 8 up to 256). As expected, each line maintains low latency until a saturation point when throughput begins to peak and latencies increase as clients have to wait longer for the overloaded server to respond. The more clients there are, the more chances for transactions to contend. We see that the baseline reader/writer locking scheme falls over very early on this reasonably contentious workload, as writes to the popular keys cause others to abort.

We see that enabling phasing (the dashed lines) immediately helps even the reader/writer locks by ensuring that all clients get processed in order of arrival. However, enabling boosting, which switches to using abstract locks, prevents `insert` operations from aborting each other, nearly doubling throughput by exposing more concurrency, and combining adds a little more on top of that. Importantly, `insert` does not generally commute with `size` (except in the case where a duplicate is added), so there is still a significant chance for conflicts in this workload.

~ Fig { #plot-mix caption="*Peak throughput, varying operation mix.* For read-heavy workloads, using commutativity (boosting) is irrelevant, but with a greater fraction of commutative updates, reader/writer locking falls over while boosting maintains high throughput." }
![Varying mix](plots/rawmix-mix.pdf){ .onecol }
~

### Varying operation mix

[#plot-mix] shows throughput as we vary the percentage of commutative write operations (in this case, set insertions). Reader/writer locks and abstract locks are identical for an all-read workload, as the far-left data points demonstrate. However, as we move to the right, the more (commutative) writes there are, the more separation there is between the two, though overall, more writes involves more work, so overall throughput decreases. Phasing (dashed lines) is most important for the mixed workloads in the middle because it helps re-order operations so they can commute — without it, operations that commute must get lucky and arrive at nearly the same time. Finally, combining gives a slight advantage over just boosting as it reduces load on the servers.

### Varying key distribution

~ Fig { #plot-zipf caption="*Peak throughput, varying key distribution.* Higher zipfian results in greater contention; abstract locks, used in boosting and phasing, perform better. Phasing alone is ineffetual." }
![Varying zipfian](plots/rawmix-zipf.pdf){ .onecol }
~

Our final way to control contention is to vary the zipfian parameter used to select keys. [#plot-zipf] shows throughput results for a 50%-write workload with varying key distributions. At the smallest zipfian, our optimizations have only a modest impact (this is still a rather write-heavy workload), as most operations are concurrent simply because they fall on different records. As the distribution becomes more skewed toward fewer keys, there is less inter-record concurrency, so we rely more on our optimizations to extract concurrency within a record. Boosting exposes concurrency between insert operations, and phasing ensures that the hot records process operations as efficiently as possible. At especially high skew, combining finally becomes a significant help: when operations succeed in combining at the client side, it relieves the servers of some load. Because the "clients" in our model are likely to be application servers handling many concurrent end-user requests, it becomes feasible to maintain high throughput writes even under extreme contention, provided they commute.

Now that we understand how these optimizations perform under various degrees of contention, we turn to some benchmarks that model contention in real-world scenarios.

## RUBiS

The RUBiS [@Amza:02] benchmark imitates an online auction service similar to those described back in [#sec-realworld]. There are 8 different kinds of transactions: `OpenAuction`, `ViewAuction`, `CloseAuction`, `Bid`, `Browse`, `AddComment`, `AddUser`, `ViewUser`, but `ViewAuction` and `Bid` dominate the workload. The benchmark specifies a workload consisting of a mix of these transactions and the average number of bids per auction that should result. However, the *distribution* of bids (by item and time) was left unspecified.

~ Fig { #plot-bid-dist caption="Our modified Rubis models real-world auctions with bids per item (*left*) which follow a power law (indicated by a straight line on a log-log plot), and the frequency of bids over the auction time window (*right*), with higher bidding rates closer to closing time. These skewed distributions, which match those observed empirically, lead to bursts of high contention." }
![Rubis distributions](plots/bid-dist.pdf){.onecol}
~

Our modified implementation correctly models the bid distributions observed by prior studies [@Akula:04;@Akula:07], with bids per item following a power law distribution and the frequency of bids increasing exponentially at the end of an auction ([#plot-bid-dist]). Otherwise, we follow the parameters specified in [@Amza:02]: 30,000 items, divided into 62 regions and 40 categories, and 1M users, with an average of 10 bids per item, (though in our case this is distributed according to a zipfian distribution with a parameter of 1.0.

~ Fig { #plot-rubis caption="Throughput of Rubis. Contention between bids on popular auctions, especially close to their closing time, causes performance to drop for reader/writer locks, but tracking top bids is commutative, so boosted transactions maintain high throughput and lower latency." }
![Rubis](plots/rubis-tput.pdf){ .onecol }
~

[#plot-rubis] shows the performance results for two different workloads: read-heavy (10% Bid transactions), and bid-heavy (50% bid transactions). For the read-heavy workload, phasing and boosting accomplish the same thing, both preventing the occasional performance breakdown which leads the baseline to suffer. In this case, reader/writer locks with phasing are sufficient because the workload is mostly reads. However, in the more bid-heavy workload there is more contention, especially on the most popular auctions, which reader/writer locks are unable to cope with. By taking advantage of the fact that bids commute with each other, boosting maintains nearly the same throughput as on the read-heavy workload.

~ Fig { #plot-rubis-conflicts caption="Breakdown of conflicts between Rubis transactions (minor contributors omitted) with 256 clients on bid-heavy workload (averaged). Note that, as predicted by [#fig-rubis-conflicts], boosting completely eliminates Bid-Bid conflicts, and phasing drastically reduces remaining conflicts." }
![Rubis](plots/rubis-conflicts.pdf){ .onecol }
~


~ Fig { #plot-rubis-samples caption="Trace of throughput over time for Rubis (both with phasing enabled). The workload is characterized by bursts of high-contention bidding activity. Boosting smooths out the performance, reducing variance by 2.8x."}
![Rubis sampled throughput](plots/rubis-samples.pdf){.onecol}
~

In fact, boosting and combining both serve to avoid performance breakdowns during high-contention times. [#plot-rubis-samples] shows some traces of executions (eliding the unrepresentative startup and tail ends). We can see that the baseline's throughput plummets periodically during bursts of bidding as popular auctions near close. Leveraging commutativity with boosting helps reduce these contention spikes, maintaining smoother performance.


## Retwis

Retwis is a simplified Twitter clone designed originally for Redis [@redis]. Data structures such as sets are used track each user's followers and posts and keep a materialized up-to-date timeline for each user (represented as a sorted set). On top of Retwis's basic functionality, we added a "repost" action that behaves like Twitter's "retweet". Not being a true benchmark itself, Retwis doesn't specify a workload, so we simulate a realistic workload using a synthetic graph with power-law degree distribution and a simple model for user behavior for posting and reposting.

~ Fig { #plot-retwis-dists caption="Power-law distributions in our Retwis benchmark. Distribution of followers per user (*left*) comes from the Kronecker synthetic graph generator. Number of reposts per post (*right*) is a result of the graph structure and our user model which favors reposting already-popular posts." }
![Retwis power-law distributions](plots/retwis-dists.pdf){ .onecol }
~

For our synthetic graph, we use the Kronecker graph generator from the Graph 500 benchmark [@graph500]. This generator is designed to result in graphs with the same power-law degree distribution found in natural graphs. Our experiments use a Kronecker graph of approximately 65,000 users, with an average number of followers of 16 (scale 16 with an edge-factor of 16 in Graph500's terms). [#plot-retwis-dists] (left) shows that the distribution of followers per user follows a power law as intended.

We use a simple model of user behavior to determine when and which posts to repost. Each time we load the most recent posts in a timeline for a random user (uniformly selected), they are sorted by the number of times they have already been reposted, and a discrete geometric distribution (skewed toward 0) is used to select the number of these to repost. The distribution of reposts resulting from our model is shown in [#plot-retwis-dists] (right), which follows a power law distribution: a decent approximation of the "viral" propagation effect observed in real social networks. Note that a small number of posts are reposted so much that they end up on over a quarter of users' timelines.

~ Fig { #plot-retwis caption="Throughput vs latency plot of Retwis. Boosting and phasing are essential for posting and re-posting, which have significant commutativity, which is reflected in a significant difference in scalability even for the read-heavy workload." }
![Retwis](plots/retwis-tput.pdf){ .onecol }
~

[#plot-retwis] shows the performance of Retwis on Claret. The post-heavy workload represents a period of time with an above-average amount of posting, especially reposting, which corresponds to the performance during peak traffic times, such as during live events, where new posts are constantly flooding in, or when posts are propagating virally. In Retwis, posting involves pushing the new post to the timelines of all the poster's followers in order to avoid costly queries later when loading timelines. Doing this transactionally completely fails with traditional reader/writer concurrency control, but because adding to timelines is commutative, boosting and phasing together allow it to scale. On a more read-heavy workload, which inherently has less work due to much simpler read transactions, throughput scales better with more clients. However, even with significantly less posting activity, commutativity still plays an important role in overall performance because slow post transactions can prevent others from reading their timelines.

It is worth noting that for the most part, in social networks it is considered acceptable to perform actions non-transactionally, because correctness is not critical. This tradeoff is clear when performance is as flat as the reader/writer performance is in these plots. With the improved scaling afforded by Claret's ADTs, however, there may be more places where it makes sense to choose correctness. This embodies the philosophy behind Claret: if the true concurrency in the application can be exposed, then correctness need not be sacrificed. In other applications, like auctions, where contention is common but correctness cannot as easily be forsaken, techniques which expose concurrency are essential. By leveraging the data structures programmers naturally choose to use, Claret exposes concurrency without burdening developers.
