# Evaluation

## Raw Operation Mix

~ Fig { #plot-rawmix caption="Performance of raw mix workload (50% read, zipf: 0.6) while increasing number of clients, plotted as throughput versus latency. We see that phasing helps all modes avoid latency spikes by ordering lock requests fairly, and when used with abstract locks and combining, results in much higher peak throughput, with no increase latency." }
![Raw mix throughput versus latency](plots/rawmix-tput-vs-lat.pdf){ .onecol }
~

~ Fig { #plot-mix caption="Peak throughput, varying operation mix. For read-heavy workloads, using commutativity (boosting) is irrelevant, but with a greater fraction of commutative updates, reader/writer locking falls over while boosting maintains high throughput." }
![Varying mix](plots/rawmix-mix.pdf){ .onecol }
~

~ Fig { #plot-zipf caption="Peak throughput with varying workload skew. Higher zipfian results in greater contention; abstract locks, used in boosting and phasing, perform better. Phasing alone is ineffetual." }
![Varying zipfian](plots/rawmix-zipf.pdf){ .onecol }
~

### Boosting

### Phasing

### Combining


## Rubis

~ Fig { #plot-rubis caption="Throughput vs latency plot of Rubis (auction site). Contention between bids on popular auctions, especially close to their closing time, causes performance to drop for reader/writer locks, but tracking top bids is commutative, so boosted transactions maintain high throughput and lower latency." }
![Rubis](plots/rubis-tput-vs-lat.pdf){ .onecol }
~

## Retwis

~ Fig { #plot-retwis-no-async caption="Throughput vs latency plot of Retwis. Even for steady-state read-heavy workload, boosting and combining are essential for acheiving good throughput. Data points with exceedingly high failure rate are left out (almost all non-phasing)." }
![Retwis](plots/retwis-tput-vs-lat-no-async.pdf){ .onecol }
~

## Social Network Benchmark
(??)
