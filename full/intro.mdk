# Introduction {#intro}

Reading is easy. Reads don't invalidate other reads, so they can all happen concurrently, making them loved by all in distributed systems. Truly read-only workloads, such as browsing static pages or viewing media-rich content, are relatively easy to scale using geo-replication and caching. Writes, on the other hand, cause conflicts.
The steady increase in interactive applications like social networks has resulted in more mixed workloads with writes causing significant conflicts. Even content consumption results in writes as providers track user behavior in order to personalize their experience, target ads, or collect statistics [@summingbird].

Today's online ecosystem is dominated by viral behavior, with memes constantly propagating through social networks, blogs, and news sites, causing one page, post, or tweet to be suddenly inundated with load, crashing systems that are unprepared.
When Ellen Degeneres posted a selfie at the Oscars in 2014, it was retweeted so much and so quickly that Twitter briefly slowed to a standstill [@ellenselfie].
Many applications that interact with real world systems exhibit similarly skewed access patterns. When those accesses include writes, the resulting contention severely inhibits scaling.

To avoid catastrophic failures and mitigate poor tail behavior, significant engineering effort must go into handling these challenging high-contention scenarios. The reason writes are such a problem is that they require synchronization to impose the ordering constraints necessary to provide any amount of consistency. Luckily, many of these orderings are actually irrelevant from the perspective of the application: some actions are inherently acceptable to reorder. For example, it is not necessary to keep track of the order in which people retweeted Ellen's selfie.

One way to avoid unnecessary constraints is to use eventual consistency, but then applications must deal with inconsistent data, especially in cases with high contention. However, if systems could directly use these application-level constraints to expose concurrency and avoid over-synchronizing, they could eliminate many false conflicts and potentially avoid falling over during writing spikes, without sacrificing correctness. Databases and distributed systems have long used properties such as commutativity to reduce coordination and synchronization. The challenge is always in communicating these application-level properties to the system.

In this work, we propose a new way to express high-level application semantics through *abstract data types* (ADTs) and consequently avoid unnecessary synchronization in distributed transactional datastores. ADTs allow users and systems alike to reason about their logical behavior, including algebraic properties like commutativity, rather than the low-level operations used to implement them. Datastores can leverage this higher-level knowledge to avoid conflicts, allowing transactions to interleave and execute concurrently without changing the observable behavior. Programmers benefit from the flexibility and expressivity, reusing data structures from a common library or extending it with custom ADTs to match their specific application.

Our prototype ADT-store, *Claret*, demonstrates how ADT awareness can be added to a common datacenter model to make strongly consistent distributed transactions practical. Rather than requiring a relational data model with a fixed schema, Claret encourages programmers to use whatever data structures naturally express their application. It is the first non-relational system to leverage ADT semantics to reduce conflicts between distributed transactions.

Datastores supporting complex datatypes and operations are already popular. Many [@cassandra;@voldemort] support simple collections such as *lists*, *sets*, and *maps*, and even custom objects (e.g. protocol buffers). Redis [@redis], one of the most popular key/value stores, supports a large, fixed set of complex data types and a number of operations specific to each type. Currently, these datastores treat data types as just blackboxes with special update functions.

In *Claret*, we expose the logical properties of these data types to the system, communicating properties of the application to the datastore so it can perform optimizations on both the client and server side. On high-contention workloads, the combined optimizations achieve up to a [todo: 49x] improvement in transaction throughput over traditional concurrency control on a synthetic microbenchmark, up to [todo: 68x] on an auction benchmark based on Rubis [@Amza:02], and [todo: 4x] on a Twitter clone based on Retwis [@retwis]. While Claret's optimizations help most in high-contention cases, its performance on read-heavy workloads with little contention is not affected. Additionally, Claret's strongly consistent transactions can typically achieve within [todo: 67%] of the same workload executed directly, without transactions.

This work makes the following contributions:
- Design of an *extensible ADT-store*, Claret, with interfaces to express logical properties of new ADTs
- Implementation of optimizations leveraging ADT semantics: *transaction boosting*, *operation combining*, and *phasing*
- Evaluation of the impact of these optimizations on raw transaction performance and benchmarks modeling real-world contention

In the remainder of this paper we will describe the design of the system and evaluate the impact ADT-enabled optimizations have on transaction performance. But first, we must delve more deeply into what causes contention in real applications.
