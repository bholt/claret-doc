# Introduction {#intro}

One of the most challenging situations to deal with in any concurrent system is contention on a shared resource or piece of data. Contention can take many forms, but the fundamental challenge is that synchronization is required to allow many entities to perform updates in a consistent manner. This can be a particular problem for distributed systems; bringing additional machines to bear on a problem not only means adding more entities which could conflict with each other but also necessarily increases the cost of synchronization. High-contention cases can end up funneling many concurrent clients down to a small number of nodes which have the necessary data or perform synchronization.

Some applications scale out well â€” larger data sets providing more room to "spread out" and go without interaction. However, systems interacting with the real world often exhibit common patterns which are challenging: low-diameter networks ("small-world" property of social networks), activity spikes resulting from realtime events (tweets following a World Cup goal), and skewed popularity of content (trending tags, viral memes). If these workloads were truly read-only then replication could solve many of the problems, but many cases involve user interaction which leads to contention. Even content consumption workloads can present a challenge as providers track user behavior in order to personalize their experience, target ads, or collect aggregate statistics.

Luckily, many of these high-contention cases share other properties which can save us such as commutativity and associativity. Properties like these expose additional concurrency, relaxing synchronization constraints and allowing operations to be parallelized and distributed. For instance, keeping track of the maximum bid of an online auction is a commutative operation, so we can reduce an extremely high volume of bids down to a unique winner in parallel. The problem is that most of these properties which exist at the application level are lost in translation to the lower-level interfaces of the datastores which are typically used to implement large-scale interactive applications.

Consider the case of an online auction service: the most popular auctions will have orders of magnitude more bids than the average case, with bids coming faster as closing time approaches [@Menasce:2007]. Represented naively as a couple records tracking the item information and current maximum bid leads to extreme contention as all the clients attempt to win the bid. The datastore, not knowing the semantics of the operations, must serialize them. Regardless of the implementation of the storage system, this is clearly a bottleneck, leading to backed-up queues, fewer bids, and a worse experience for users. If the datastore knew that the operations commuted, it could potentially process them in parallel, eliminating some bids before they ever reach the contended record.

The challenge is how to express these application properties to the datastore in a way that it can use the knowledge to improve processing under contention, without giving up the flexibility or scalability these systems espouse. We propose a richer interface already familiar to programmers and systems alike: *abstract data types* (ADTs). Datastores should expose an extensible library of complex data structures as their interface rather than restricting values to strings of bytes.
This programming model has several advantages for users:

- *Flexibility:* ADTs retain the flexibility of key-value stores, still no need for global schemas
- *Semantics:* Programmers express application semantics by choosing or implementing specific ADTs
- *Modularity:* Common data structures can be *reused* or *composed* in new applications, leveraging prior optimization effort.

The abstraction also affords opportunities to the datastore:

- High-level properties of ADT operations (e.g. commutativity) expose more concurrency and flexibility.
- Common properties can be leveraged to perform the same optimizations to many different ADTs.
- ADTs implement modular logic to help the datastore parallelize their operations.

Some datastores are already moving in this direction; several already support more complex datatypes like sorted sets. Redis, currently the most popular key-value store, supports a large number of operations on records of various types. However, to the best of our knowledge, these datatypes are used for little more than supporting more complex atomic operations like set addition. The higher-level properties of operations such as their commutativity are not leveraged by the system to distribute processing of a single record or otherwise avoid contention. Developers are still required to build their own mechanisms for avoid contention into their applications. In addition, they rarely support extending them with new data types, which restricts opportunities for tailoring data types to the use case at hand.

In this work, we explore what the ADT programming model has to offer datastores. We describe some properties of ADTs and show how they could be expressed to the datastore. We then show how these properties could be used by optimizations to avoid contention, specifically *transaction boosting* and *combining* and evaluate the performance benefits of each. Finally, we identify contention problems in benchmarks based on real applications and demonstrate how the techniques we have described allow the datastore to mitigate them.
