# Enforcing consistency policies {#sec-enforcing}
The consistency policies introduced in the previous section allow programmers to describe application-level correctness properties. Static consistency policies (e.g. Strong) are enforced by the underlying storage system; the annotated ADT methods simply set the desired consistency level when issuing requests to the store.
The dynamic policies each require a new runtime mechanism to enforce them: parallel operations with latency monitoring for latency bounds, and reusable reservations for error tolerance. But first, we briefly review consistency in Dynamo-style replicated systems.

<!-- To be sure of seeing a particular write, *strong* reads must coordinate with a majority (*quorum*) of replicas and compare their responses. -->
To be sure a strong read sees a particular write, the two must be guaranteed to coordinate with overlapping sets of replicas (*quorum intersection*).
For a write and read pair to be *strongly consistent* (in the CAP sense [@Brewer:CAP]), the replicas acknowledging the write ($W$) plus the replicas contacted for the read ($R$) must be greater than the total number of replicas ($W + R > N$). This can be achieved, for example, by writing to a quorum ($(N+1)/2$) and reading from a quorum (`QUORUM` in Cassandra), or writing to $N$ (`ALL`) and reading from 1 (`ONE`) [@CassandraConsistency].

Because overall consistency is dependent on both the strength of reads *and* writes, it really does not make sense to specify consistency policies on individual operations in isolation. Declaring consistency policies on an entire ADT, however, allows the implementer of the ADT to ensure that all combinations of reads and writes achieve the specified consistency.

## Static bounds

Static consistency policies are typically enforced by the underlying datastore, but they require the designer of each ADT to carefully choose how to implement them. To support the `Consistency(Strong)` policy, the designer of each ADT must choose consistency levels for its operations which together enforce strong consistency. For example, if a developer knows that updates to a `Counter` are more common, they may choose to require the `read` operation to synchronize with all replicas (`ALL`), permitting `increment` and `decrement` to wait for only a single replica (`ONE`) without violating strong consistency.

## Latency bounds {#sec-latency-bounds}
The time it takes to achieve a particular level of consistency depends on current conditions and can vary over large time scales (minutes or hours) but can also vary significantly for individual operations. During normal operation, strong consistency may have acceptable performance while at peak traffic times the application would fall over. Latency bounds specified by the application allow the system to *dynamically* adjust to maintain comparable performance under varying conditions.

<!--
It is conceptually quite simple to implement a dynamically tunable consistency level: send read requests to as many replicas as necessary for strong consistency (depending on the strength of corresponding writes it could be to a quorum or all), but then when the latency time limit is up, take however many responses have been received and compute the most consistent response possible from them.
-->

Our implementation of latency-bound types takes a generic approach: it
issues read requests at different consistency levels in parallel. It
composes the parallel operations and returns a result either when the
strongest operation returns, or with the strongest available result at
the specified time limit. If no responses are available at the time
limit, it waits for the first to return.

This approach makes no assumptions about the implementation of read
operations, making it easily adaptable to different storage
systems. Some designs may permit more efficient implementations: for
example, in a Dynamo-style storage system we could send read requests
to all replicas, then compute the most consistent result from all
responses received within the latency limit. However, this requires
deeper access to the storage system implementation than is
traditionally available.

### Monitors

The main problem with our approach is that it wastes work by issuing
parallel requests. Furthermore, if the system is responding slower due to a sudden surge in traffic, then it is essential that our efforts not cause additional burden on the system.
In these cases, we should back off and only attempt weaker consistency.
To do this, the system monitors current traffic and predicts the latency of different consistency levels.

Each client in the system has its own Monitor (though multi-threaded clients can share one). The monitor records the observed latencies of reads, grouped by operation and consistency level. 
<!-- Our ADTs are implemented in terms of Cassandra *prepared statements*, so we can easily categorize operations by their prepared identifier.  -->
The monitor uses an exponentially decaying reservoir to compute running percentiles weighted toward recent measurements, ensuring that its predictions continually adjust to current conditions. 

Whenever a latency-bound operation is issued, it queries the monitor to determine the strongest consistency likely to be achieved within the time bound, then issues one request at that consistency level and a backup at the weakest level, or only  weak if none can meet the bound. In [#eval-latency-bounds] we show empirically that even simple monitors allow clients to adapt to changing conditions.

<!-- 
### Adjusting write level
Remember that the achieved consistency level is determined by the combination of the write level and read level. By default, we assume a balanced mix of operations on an ADT, so writes are done at `QUORUM` level and strong reads can be achieved with the matching `QUORUM` level. However, sometimes this is not the case: if a datatype is heavily biased toward writes, then it is better to do the weakest writes, and adjust reads to compensate. It is up to the ADT designer to determine what is best for their intended use case. Our implementations use a static write level so the strength of reads can be determined without checking, though an ambitious ADT designer could have theirs make decisions at runtime about the read/write balance, provided they handle reads correctly during transitions.
 -->

## Error bounds { #sec-reservations }
We implement error bounds by building on the concepts of *escrow* and *reservations* [@ONeil:86;@Gawlick:85;@Reuter:82;@Preguica:03]. These techniques have been used in storage systems to enforce hard limits, such as an account balance never going negative, while permitting concurrency. 
The idea is to set aside a pool of permissions to perform certain update operations (we'll call them *reservations* or *tokens*), essentially treating *operations* as a manageable resource. If we have a counter that should never go below zero, there could be a number of *decrement* tokens equal to the current value of the counter. When a client wishes to decrement, it must first acquire sufficient tokens before performing the update operation, whereas increments produce new tokens. The insight is that the coordination needed to ensure that there are never too many tokens can be done *off the critical path*: tokens can be produced lazily if there are enough around already, and most importantly for this work, they can be *distributed* among replicas. This means that replicas can perform some update operations safely without coordinating with any other replicas.

### Reservation Server
Reservations require mediating requests to the datastore to prevent updates from exceeding the available tokens. Furthermore, each server must locally know how many tokens it has without synchronizing. 
We are not aware of a commercial datastore that supports custom mediation of requests and replica-local state, so we need a custom middleware layer to handle reservation requests, similar to other systems which have built stronger guarantees on top of existing datastores [@Balegas:15:BoundedCounter;@Bailis:13:Bolt;@Sivaramakrishnan:15:Quelea].

Any client requests requiring reservations are routed to one of a number of *reservation servers*. These servers then forward operations when permitted along to the underlying datastore. All persistent data is kept in the backing store; these reservation servers keep only transient state tracking available reservations. The number of reservation servers can theoretically be decoupled from the number of datastore replicas; our implementation simply colocates a reservation server with each datastore server and uses the datastore's node discovery mechanisms to route requests to reservation servers on the same host.

### Enforcing error bounds
Reservations have been used previously to enforce hard global invariants in the form of upper or lower bounds on values [@Balegas:15:BoundedCounter], integrity constraints [@Balegas:15:Indigo], or logical assertions [@Liu:14:Warranties]. However, enforcing error tolerance bounds presents a new design challenge because the bounds are constantly shifting.
Consider a `Counter` with a 10% error bound, shown in [#fig-reservations]. If the current value is 100, then 10 increments can be done before anyone must be told about it. However, we have 3 reservation servers, so these 10 reservations are distributed among them, allowing each to do some increments without synchronizing. If only 10 outstanding increments are allowed, reads are guaranteed to maintain the 10% error bound.

~ Fig { #fig-reservations caption="*Enforcing error bounds on a Counter:* (A) Each replica has some number of tokens allocated to it, must add up to less than the max (in this case, 10% of the current value). (B) Reservation Server 1 has sufficient tokens available, so both increments consume a token and proceed to Replica 1. (C) Reads return the range of possible values, determined by total number of allocated tokens; in this case, it reads the value 100, knows that there are 10 tokens total, but 5 of them (local to RS2) are unused, so it returns 100..105. (D) *Eventually,* when the increments have propagated, reservation server reclaims its tokens.[\vspace{-10pt}]{input:texraw}" }
![](fig/reservations.pdf)
[\vspace{-16pt}]{input:texraw}
~

In order to perform more increments after a server has exhausted its reservations, it must synchronize with the others, sharing its latest increments and receiving any changes of theirs. This is accomplished by doing a strong write (`ALL`) to the datastore followed by a read. Once that synchronization has completed, those 3 tokens become available again because the reservation servers all temporarily agree on the value (in this case, at least 102).

Read operations for these types go through reservation servers as well: the server does a weak read from any replica, then determines the interval based on how many reservations there are. For the read in [#fig-reservations], there are 10 reservations total, but Server B knows that it has not used its local reservations, so it knows that there cannot be more than 6 and can return the interval $[100,106]$.

### Narrowing bounds
Error tolerance policies set an *upper bound* on the amount of error; ideally, the interval returned will be more precise than the maximum error when conditions are favorable, such as when there are few update operations.
Rather than assuming the total number of tokens is always the maximum allowable by the error bound, we instead keep an *allocation table* for each record that tracks the number of tokens allocated to each reservation server. If a reservation server receives an update operation and does not have enough tokens allocated, it updates the allocation table to allocate tokens for itself. The allocation table must preserve the invariant that the total does not exceed the maximum tokens allowed by the current value. For example, for a value of 100, 10 tokens were allowed, but after 1 decrement, only 9 tokens are allowed. Whenever this occurs, the server that changed the bound must give up the "lost" token out of its own allocations. As long as these updates are done atomically (in Cassandra, this is done using linearizable conditional updates), the global invariant holds.
Because of this synchronization, reading and writing the allocation table is expensive and slow, so we use long leases (on the order of seconds) within each reservation server to cache their allocations. When a lease is about to expire, the server preemptively refreshes its lease in the background so that writes do not block unnecessarily.

For each type of update operation there may need to be a different pool of reservations. Similarly, there could be different error bounds on different read operations. It is up to the designer of the ADT to ensure that all error bounds are enforced with appropriate reservations. Consider a `Set` with an error tolerance on its `size` operation. This requires separate pools for `add` and `remove` to prevent the overall size from deviating by more than the bound in either direction, so the interval is $[v-\texttt{remove.delta},v+\texttt{add.delta}]$ where $v$ is the size of the set and `delta` computes the number of outstanding operations from the pool.
In some situations, operations may produce and consume tokens in the same pool – e.g., `increment` producing tokens for `decrement` – but this is only allowable if updates propagate in a consistent order among replicas, which may not be the case in some eventually consistent systems.

<!-- It is tempting to try to combine reservations for inverse operations into the same pool. For instance, it would seem that decrements would cancel out increments, allowing a single reservation server receiving matching numbers of each to continue indefinitely. In some situations, such as if sticky sessions can guarantee ordering from one reservation server to one replica, this could be sound. However, in the general case of eventual consistency, this is not valid, as the increments and decrements could go to different replicas, or propagate at different rates. Therefore it is crucial that ADT designers think carefully about the guarantees of their underlying datastore. Luckily, the abstraction of ADTs hides this complexity from the user — as long as the ADT is implemented correctly, they need only worry about the stated error bounds. -->
