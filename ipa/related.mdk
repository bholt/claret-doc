# Related Work

**Consistency models.**
IPA's consistency types could be extended to more of the
thriving ecosystem of consistency models from *sequential
consistency* [@Lamport:79:SC] and *linearizability*
[@Herlihy:90:Linear], to *eventual consistency*
[@Vogels:EC]. A variety of intermediate models
fit elsewhere in the spectrum, each making different trade-offs
balancing performance against ease of
programming. Session guarantees, including *read-your-writes*,
strengthen ordering for individual clients but reduce availability
[@Terry:94:Session].  Many datastores allow fine-grained consistency control: Cassandra [@cassandra] per operation, Riak
[@riak] on an object granularity, and others
[@Li:12:RedBlue;@Sovran:11:Walter].  The Conit consistency model
[@Yu:02:Conit] breaks down the consistency spectrum into numerical
error, order error, and staleness, but requires annotating each
operation and explicit dependency tracking, rather than annotating
ADTs.

**Higher-level consistency requirements.**
Some programming models
allow users to express application correctness criteria
directly.  In Quelea [@Sivaramakrishnan:15:Quelea], programmers write
*contracts* to describe *visibility* and *ordering* constraints and the system selects the necessary consistency. In Indigo [@Balegas:15:Indigo], programmers write
*invariants* over abstract state and annotate post-conditions on
actions in terms of the abstract state and the system adds coordination logic, employing reservations for numeric bounds. Neither
Indigo nor Quelea, however, allow programmers to specify
approximations or error tolerances, nor do they enforce any kind of
performance bounds.

IPA's latency-bound policies were inspired by Pileus's [@Terry:13:SLAs] *consistency-based SLAs*. Consistency SLAs specify a target
latency and consistency level (e.g. 100 ms with read-my-writes),
associated with a *utility*. Each operation specifies a set of SLAs,
and the system predicts which is most likely to be met, attempting to
maximize utility, and returns both the value and the achieved
consistency level. Other systems, including PRACTI
[@Belaramani:06:PRACTI], PADS [@Belaramani:09:PADS], and WheelFS
[@Stribling:09:WheelFS], have given developers ways of expressing
their desired performance and correctness requirements through
*semantic cues*.

<!--
Probabilistically bounded staleness (PBS) [@Bailis:12:PBS] are a form of performance and correctness bound. Using a predictive model, PBS is able to quantify the degree of inconsistency that is likely for a given operation, but it has not been used to directly improve programming models. This kind of knowledge could be applied within IPA's runtime system to make better latency predictions or to provide a new IPA probabilistic IPA type similar to `Interval[T]`.
-->

The principle that applications may be willing to tolerate slightly stale data in exchange for improve performance has a long history in databases [@roehm02:_fas;@plattner04:_ganym;@bernstein06:_relax_curren_serial_for_middl;@pu91:_replic_contr_distr_system] and distributed caches [@ports10:_trans_consis_autom_manag_applic_data_cache;@olston99:_adapt_precis_settin_cached_approx_values]. These systems generally require developers to explicitly specify staleness bounds on each transaction in terms of absolute time (although Bernstein et al.'s model can generate these from error bounds when a value's maximum rate of change is known).

The above techniques are relevant but largely orthogonal to our work:
they provide techniques which could be used in IPA
to trade off correctness in new ways. This work builds on those
insights, introducing a new error tolerance mechanism, proposing
ADT annotations rather than per-operation, but most importantly,
providing *consistency safety* via consistency types, which ensure
that all possible cases are handled whenever the system adjusts
consistency to meet performance targets. Previous systems gave some
feedback to programs about achieved consistency, but did not provide
facilities to ensure developers use the information
correctly.


<!-- [todo: are there other systems with explicit performance bounds enforced by the system?] -->


<!-- ## Controlling staleness --> <!-- Most eventually consistent
models provides no guarantees about how long it will take for updates
to propagate. However, there are several techniques to help bound the
staleness of reads. -->

<!-- *Leases* are an old technique that essentially gives reads an
*expiration date*: the datastore promises not to modify the value that
was just read until the lease term is over. First proposed to avoid
explicit invalidations in distributed file system caches [@Gray:89],
leases have since been used in a multitude of ways: in Facebook's
Memcache system [@Nishtala:13:Memcache] for invalidations, Google's
Chubby [@Burrows:2006:Chubby] and Spanner [@Spanner] to adjust the
frequency of heartbeat messages, and on mobile clients with exo-leases
[@Shrira:08:ExoLeasing]. Warranties [@Liu:14:Warranties] are a
generalization of leases, allowing arbitrary assertions over state or
behavior. [todo: explain how our leases relate (if they get
implemented)] -->


**Types for approximation.**
IPA's type system is inspired by
work on *approximate computing*, in which computations can be
selectively made inaccurate to improve energy efficiency and
performance. EnerJ [@Sampson:11:EnerJ;@Boston:15:DECAF] and Rely
[@Carbin:13:Rely;@Misailovic:14:Chisel] track the flow of approximate
values to prevent them from interfering with precise
computation. IPA's interval types are similar to Uncertain&lt;T&gt;'s
probability distributions [@Bornholt:14:UncertainT] and to interval
analysis [@Moore:66:IA]. One key difference for IPA is that
inconsistent values can be strengthened if desired with additional
synchronization.

**Types for distributed and secure systems.**
*Convergent* (or *conflict-free*) *replicated data types* (CRDTs)
[@Shapiro:SSS11:CRDT] are data types designed for eventual
consistency that guarantee convergence by forcing all updates to commute. 
CRDTs can be useful because they allow
concurrent updates with meaningful semantics, but they are still only
eventually (or causally) consistent, so users must still deal with
temporary divergence and out-of-date reads, and they do not
incorporate performance bounds or variable accuracy. The Bounded Counter CRDT [@Balegas:15:BoundedCounter] informed the design of our reservations for error bounds, but enforces global value bounds and does not bound uncertainty.
Information flow tracking systems
[@myers99:_jflow;@sabelfeld03:_languag_based_infor_flow_secur;@denning77:_certif],
also use static type checking and dynamic analysis to enforce
*non-interference* between sensitive data and untrusted channels, but,
to the best of our knowledge, those techniques have not been applied
to enforce consistency safety by separating weakly and strongly
consistent data.

