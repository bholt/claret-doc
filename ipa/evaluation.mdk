# Evaluation
[todo: explain how we simulate network conditions using `tc netem` and `docker` üê≥]

~~ Notes
- applications in datacenters, geo-replicated, exposed to the Internet, have to be able to handle a wide range of conditions
- plan for worst-case conditions
- provide structure/discipline to ensure programmers have handled all the things that can go wrong
- provide system with hints about what it should prioritize, and release valves to allow it to still be useful when times are tough
- robust to changes in the environment
- in our evaluation, we need to establish
	- these bounds actually can be enforced without being detrimental to performance
	- that they reliably 
~~

Distributed applications must be able to run in a constantly changing environment. IPA's types provide structure that helps programmers ensure their application handles all potential edge cases. The bounds specified by programmers give them control over how the application will adjust to changing conditions, but they also provide the system with hints about what it should prioritize, and release valves that allow it to still be useful even performance has degraded.

To evaluate these bounding techniques, it is crucial to subject them to a variety of conditions. One typically has two two extreme choices when evaluating this kind of system: perform experiments in a controlled environment where latencies are typically very low and performance variability is negligible, or to throw them into a complex, real-world system, subject to the whims of unpredictable network conditions and resource sharing and try to piece together how they performed. A third option is to *simulate* a variety of environments, chosen to stress the system or mimic reality, within a more controlled environment. 

In our experiments, we employ all three to best understand how these techniques behave. On our own test cluster, with standard ethernet linking nodes within the same rack, we run controlled experiments, simulating adverse network conditions. We use Linux's Network Emulation facility [@netem] (`tc netem`) to introduce packet delay and loss at the operation system level. We use Docker containers [@docker] to enable fine-grained control of the network conditions between processes on the same physical node (`netem` is one of the properties isolated within the container).

[#tab-conditions] shows the set of conditions we use in our experiments to explore the behavior of the system. To simulate latencies within a well-provisioned datacenter, we have a *uniform 5ms* condition which is predictable and reliable but slower than our raw latency which is typically less than 1ms. Another condition demonstrates what happens when one replica is significantly slower to respond than the others either due to imbalanced load or hardware problems. Finally, we have two conditions mimicking globally geo-replicated setups with latency distributions based on measurements of latencies between virtual machines in the U.S., Europe, and Asia on Google Compute Engine [@GoogleCompute] and Amazon EC2 [@AmazonEC2].

In the remainder of this section, we evaluate the latency and error bounding techniques of IPA, with two main objectives:

1. Validate that they meet their stated bounds.
2. Determine if the performance of enforcing these bounds is acceptable and understand how performance is affected by different bounds.

We start with microbenchmarks to understand the performance of individual data types and explore each bound in isolation. Then we move on to some miniature applications built using these data types, employing bounds tailored to their use cases.

<!--
The environment in which these experiments are normally carried out, on isolated systems with predictable, low latencies,

In our evaluation, we wish to determine how these performance and correctness bounds 

that must handle unpredictable traffic coming in from the world, and run in a multi-datacenter environment with 

The IPA type system provides structure that helps programmers ensure their application handles all the 

The goals of IPA's abstractions are twofold: first, to give structure to help programmers ensure that their application can handle the variety of 

IPA's abstractions aim to give programmers better ways of controlling how their applications behave in order to make them robust to changes in the environment. 

The most important factor in evaluating a system like IPA is how it handles different adverse conditions. 
We wish to know how an application written using these techniques 
-->

~ Tab { #tab-conditions caption="Network conditions for experiments." }
| Condition label   | Latencies (ms)              |||
|:------------------|:-------:|:-------:|:----------|
| **Simulated**                                  ||||
| Uniform/High load | 5       | 5       | 5         |
| Slow replica      | 10      | 10      | 100       |
| Google            | 1 ¬± 0.3 | 110 ¬± 5 | 160 ¬± 5   |
| Amazon            | 1 ¬± 0.3 | 80 ¬± 10 | 200 ¬± 50  |
|-------------------|---------|---------|-----------|
| **Actual**                                     ||||
| Local             | <1      | <1      | <1        |
| Google            | 1 ¬± 0.3 | 110 ¬± 5 | 160 ¬± 5   |
|-------------------|---------|---------|-----------|
~

## Counter microbenchmark
~~ Notes
- Latency bound
	- show how it can meet various latency bounds, compared with Strong and Weak
	- show that 95th percentile still meets latency bound!
	- show how many achieved stronger consistency, and how that correlates with actual consistency violations
- Reservations
	- show link between tighter bounds and lower performance
	- tie performance to the number of strong reads/reservation refreshes we had to do
	- show how interval width gets smaller with fewer writes
~~

~ Fig { #plot-counter caption="Counter benchmark: mean latency for a random mix of counter ops (20% increment, 80% read), with various IPA bounds, under various conditions." }
![](plots/rawmix_counter.pdf){ .onecol }
~

We start by measuring the performance of a very simple application that randomly increments and reads from a number of counters with different IPA bounds. [#plot-counter] shows the average latency of a 20% increment, 80% read workload over 200 counters randomly selected using a zipfian distribution.

### Latency bounds

~ Fig { #plot-counter-lbound caption="Consistency of latency-bound operations. Strong consistency is rarely possible within 10ms. With one slow replica, most reads can still achieve strong consistency, but with high network latencies or heavy load, it degrades to use weak consistency." }
![](plots/counter_lbound.pdf){ .onecol }
~

~ Fig { #plot-counter-lbound-tail caption="Latency bounds reduce unpredictable tail latency." }
![](plots/counter_lbound_tail.pdf){ .onecol }
~

Latency bounds aim to provide predictable performance for clients while attempting to maximize consistency. Under favorable conditions, when latencies and load are low, it is often possible to achieve strong consistency. Figure [#plot-counter] shows the average latency of 

### Error bounds
We use the reservation system described in [#reservations] to enforce error bounds. Though error bounds represent a relaxation from a strict strongly consistent read, they still have 
Our goal is to explore how expensive it is in practice to enforce these error bounds, and in particular to determine if reasonable error bounds that programs could rely on are achievable with performance comparable to weak consistency.

The general intuition behind reservations is to move synchronization off the critical path: by distributing write permissions among replicas, clients can get strong guarantees while only communicating with a single replica. This shifts the majority of the synchronization burden off of reads, which are typically more common. However, this balance must be carefully considered when evaluating the performance of reservations, more so than the other techniques.

[#plot-counter] contains results for error bounds ranging from 0% to 10%, showing the average latency of both reads and increments for a mix with 20% increments. We can see that how narrow the bounds are does affect performance, but in most cases, the latency of 5-10% error bounds have roughly the same performance as weak consistency.

[todo: plot of actual error with weak consistency compared to bounded error]

~ Tab { #tab-intervals caption="Reservations adapt to varying write loads, resulting in narrower intervals (tighter error bounds) than clients requested. [todo: add more mixes, gen line plot with %reads on x axis]" }
| Error Bound | 80% read | 99% read |
|:-----------:|:--------:|:--------:|
|  0% | 0    | 0    |
|  1% | 5.4  | 0.03 |
|  5% | 45.7 | 1.36 |
| 10% | 98.2 | 3.5  |
|-----|------|------|
~

## Applications
### Shopping Cart
[todo: demonstrate loading cart with a latency bound, but not allowing users to check out without doing a strong read]

### TicketSleuth
~~ Notes
- Modeled after FusionTicket (benchmark in [@Xie:14:Salt;@Xie:15:ACIDAlt])
- Demonstrates
~~

~ Fig { #plot-tickets caption="Ticket-sales app: mean latency of `purchase` action under various conditions. The `BoundedCounter` underlying ticket sales is safe even when weakly consistent, but latency bounds allow users to see strong consistency [todo:??]% of the time, while reservations bound error to less than 5% with similar performance." }
![](plots/tickets.pdf){ .onecol }
~

[todo: ticket sales app demonstrating hard lower bounds on counters]

### Twitter clone
[todo: demonstrating error tolerance for Counter (number of retweets), and latency bound for loading the timeline]
