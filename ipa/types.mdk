# Type System

<!-- Developers of distributed applications 
today manually manage the consistency--performance trade-off.
Managing these trade-offs is error-prone 
because they require changing the consistency model 
at the granularity of individual operations.
The reliability of the resulting applications is also unclear,
because local changes in the consistency model may propagate to other operations,
and testing against every possible relaxation is difficult. -->

We propose a programming model for distributed data 
that uses types to control the consistency--performance trade-off.
Rather than changing the consistency of individual operations,
our model builds on *abstract data types* (ADTs)
annotated with consistency policies.
These *inconsistent, performance-bound, approximate types* (IPA types)
help developers trade consistency for performance in a disciplined manner.
The type system provides two important benefits:

* **Safety**: the type system tracks the consistency level of each result, and prevents inconsistent data from flowing into consistent data without explicit endorsement, in the style of EnerJ ([@TODO]).
* **Performance**: Consistency annotations on the ADT itself allow dynamic selection of consistency policies at run time

This section presents the IPA type system, 
including the available consistency policies
and the semantics of operations made under those policies.
Section [#Implementation] presents the implementation
of the IPA type system.

~~ Notes
- High-level goals
	- Explicit performance bounds (latency)
	- Explicit approximation bounds (error tolerance)
	- Results in IPA types which express the resulting uncertainty
- ADTs
	- can't just express these on the *read* side, most require knowing how the *write* was done
	- e.g. `Consistency = Read.Consistency + Write.Consistency`, so `Write.ALL + Read.ONE = Strong`, or `Write.QUORUM + Read.QUORUM = Strong`
	- Other benefits of annotating ADTs:
		- portable / reusable
		- modular
	- Similar to Indigo's ([@Indigo]) invariants, but expressing performance and approximation bounds
- Types of annotation
	- "static" bounds like `Consistency(Strong)` that fix a policy upfront
	- "dynamic" bounds like `LatencyBound(50 ms)` that choose a policy at invocation time
	- per-method bounds for ADTs (e.g. `Set[ID]` has `size` and `contains?` methods that could have different bounds)
- **Bounds**
	- `Set[ID] with Consistency(Strong)`
	- `Set[ID] with LatencyBound(50 ms) -> contains(ID): Rushed[Boolean]`
	- `Counter with ErrorTolerance(5%) -> read(): Interval[Long]`
- IPA type lattice
	- Inconsistent ($\bot$)
	- `Rushed | Interval | Leased` 
	- Consistent ($\top$)
- Rushed
	- Consistency level achieved
- Interval
	- min, max, contains?, etc
	- linearizable within the error bound -- as long as we stay within the bound, everything is strongly consistent
- Leased goes away
- Semantics of mixed consistency levels?
	- If every operation comes back strong, it's just like strong consistency was chosen in advance -- so everything is linearizable
- Futures
	- (talk about how everything is implemented with futures, or just elide that?)
- All writes are statically at a certain consistency level
	- Why? So we don't have to reason about interactions with reads (would need flow analysis)
~~
