# The Case for Consistency Safety {#sec-background}

There are many popular news stories about how services like BuzzFeed [@buzzfeed-dress] and Instagram [@bieber-instagram] struggle with unpredictable Internet traffic.
Before launching into the IPA programming model, we will explore an example application – a ticket sales service – to demonstrate the difficulties in trading off consistency to meet performance goals without breaking correctness.

In October 2015, movie ticket pre-sales became available for the much-anticipated new movie in the Star Wars franchise. The demand for these tickets was so high that many movie ticket sites, including big players such as AMC and Fandango, saw catastrophic performance drops; some smaller vendors even had crashes which resulted in loss of purchases and significant media backlash [@forbes:star-wars]. Missing the opening night of a movie may not be the most dire of circumstances, but it illustrates that web services must be prepared for all kinds of situations, even if they only happen in a minority of instances.

~ Fig { #fig-tickets; caption="Ticket sales service. To meet latency target, `load_page` switches to a weak read, introducing a potential logical error when using this possibly-inconsistent value to determine if tickets can be purchased. [\vspace{-10pt}]{input:texraw}" }
![](fig/tickets.pdf)
[\vspace{-18pt}]{input:texraw}
~

Let's look at how we would model this application using existing datastores.
In order to make our service scalable, highly available, and fault-tolerant, we can use an off-the-shelf datastore like Cassandra. Cassandra is a Dynamo-style [@DeCandia:07:Dynamo] datastore, meaning it keeps multiple complete replicas of its data, often replicating within a single datacenter and across geographically distributed datacenters. By default, clients are allowed to read or write to any available replica. Mechanisms within the datastore, such as anti-entropy, read repair, and gossip, share updates among replicas. Because propagation takes time, clients can observe many odd, inconsistent, states; updates can even appear to come and go. *Eventual consistency*, the weakest consistency typically available, only guarantees that all replicas will eventually reflect the same state some time after the last write [@Vogels:EC]. However, these datastores can provide stronger consistency by synchronizing with more replicas. Strongly consistent reads are achieved by ensuring that a *quorum* of replicas agree on a value before returning it to the client.

[#fig-tickets] shows the application's structure. Each event (in this case movie, location, and time) has some number of available tickets. Visitors to the site may browse the events or movie showings, and view individual events to see how many tickets are remaining and purchase some.

The most important invariant is that tickets are not over-sold: each available ticket must only go to one user, and the count of remaining tickets should never be below zero. However, there are also soft constraints:

- *Latency target:* Users browsing many events will become frustrated if pages take too long to load.

- *Accuracy bounds:* Users wish to know how many tickets are remaining to determine how quickly they need to purchase them.

If the latency target is not met, users may take their business to other sites. Similarly, if the remaining ticket count is off, such as if the count is stale and there are in fact fewer remaining tickets, then users may not get the tickets they wanted. 
<!-- Some amount of inaccuracy in the count is unavoidable; there is an absolute bound on the round trip time, for instance, but we may hope to keep this count as up-to-date as possible. -->

Using existing systems, we have few options for meeting all these requirements.
We can ensure that the ticket count does not go negative by forcing operations to be linearizable [@Herlihy:90:Linear;@Sivaramakrishnan:15:Quelea].
Linearizable operations (e.g., as achieved with Cassandra's "lightweight transactions") require coordination on every operation, and thus make reads of the count prohibitively slow. 
We could augment this with a second, weakly consistent counter that approximates the remaining ticket count; this must be synchronized with the true value in the other counter, and can drift arbitrarily between synchronizations. As a result, their combination introduces significant implementation complexity to keep the two counters synchronized and manage the drift of the weakly consistent counter.
Alternatively, a convergent replicated data type (CRDT) [@Shapiro:SSS11:CRDT] called a `BoundedCounter` [@Balegas:15:BoundedCounter] can enforce the invariant we want even on eventual consistency, which gives good performance and safety, but does not give us any bound on how accurate the count is at any time.

Ensuring low-latency browsing is also difficult. If we blindly use weak consistency, then users could occasionally miss new events (especially relevant to anyone refreshing waiting for Star Wars tickets), or see events that should have been deleted. If we support weak consistency, we must now handle new cases resulting from inconsistencies, such as late actions on deleted events.
During low-traffic times, allowing inconsistencies may be unnecessary. If we know the load is low, we should try to use stronger consistency to retrieve the results, and in times of heavy load, we could indicate to the user that the results may be inaccurate.
