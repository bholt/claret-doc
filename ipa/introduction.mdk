# Introduction
<!--
~~ Notes
- conditions for distributed applications running in datacenters are constantly changing
	- applications in datacenters, geo-replicated, exposed to the Internet, have to be able to handle a wide range of conditions
	- plan for worst-case conditions
	- provide structure/discipline to ensure programmers have handled all the things that can go wrong
	- provide system with hints about what it should prioritize, and release valves to allow it to still be useful when times are tough
	- robust to changes in the environment
- Applications have performance requirements
	- Sometimes explicit in the form of SLAs, promising a certain latency or availability
	- Sometimes more implicit (i.e. every additional ms of latency reduces revenue)
- Constantly balancing performance vs correctness / programmability
	- If it isn't scaling well, or latencies are too high, then relax consistency in some places and hope...
- This is error prone: every time you change consistency, there are new reorderings and conditions to consider
	- new edge cases to handle, *implicit* in the consistency model
	- accidentally leak into places that weren't intended to be weakened
- Worse: conditions can change at any moment; node goes down, network unreliable, traffic surges
	- In test environment, inconsistency is typically unlikely
	- Adverse conditions in production can cause errors that never appeared in testing, or are very difficult to test for
	- No way to know if you've caught them all
- Furthermore, when conditions are good, there's no need to resort to weak consistency
- It would be great if we had a way to:
	- Express performance bounds
		- Have the system help achieve them
	- Make inconsistency explicit and restricted
		- handle different cases in a disciplined way
		- restrict possible values, and where they can be used
- So the question is: *where to introduce this abstraction?*
	- As part of the data type!
	- Couples the effects of mutating operations with reads
	- Concise and modular: re-use data types, no annotations on individual operations
	- Safe: inconsistency expressed as return types
~~
-->

In order to provide good user experiences, modern datacenter applications and web services must balance many competing requirements. At a minimum, they must be scalable, highly available, and fault tolerant. 
On top of that, they often wish to guarantee certain response times to meet contractual service level agreements (SLAs) or to keep user engagement high; for example, Microsoft, Amazon and Google have all noted that every additional millisecond of latency translates directly to a loss in traffic and revenue [[@linden06:amazon;@forrest09:slow]. On the other hand, every application has some correctness criteria that can be hard requirements, such as never double-charging a user for a purchase, or a soft requirement like always showing the most recent tweets.

Developers of these applications typically balance these performance and correctness requirements by trading off consistency. For this reason, the scalable, replicated NoSQL datastores used to implement these services, such as Cassandra [@cassandra] and Riak [@riak], often support multiple levels of consistency: from *linearizability* all the way down to *eventual consistency*. Whenever part of an application is not scaling well, or response latencies are unacceptably high, developers can choose to perform some operations with weaker consistency. However, they must then understand what can go wrong now that new reorderings of operations are possible and handle them. Failure to do so can lead to lost updates, duplications, stale data, and more. Relaxed consistency models are notoriously difficult to understand, especially when interspersed with other models. It is easy in these situations for inconsistencies to leak into operations that were intentionally kept as strongly consistent, defeating the purpose of that choice.

Developers may change consistency to meet performance targets for one execution environment, but the conditions in which these web services operate is in constant flux. Sharing resources with many other co-located services, each of which also undergoes occasional garbage collection or operating system pauses, leads to unpredictable performance. Moreover, traffic coming in, from the outside world or via other services, can be highly unpredictable as well: whenever some meme goes viral, like Buzzfeed's black and blue dress [@buzzfeed-dress], or Justin Bieber posts a selfie [@bieber-instagram], the web service is subject to highly irregular load, overloading some nodes. In a distributed setting, interactions may typically only happen within a single datacenter, but occasionally have clients interacting across multiple geo-replicated datacenters, such as when a world-wide event like the World Cup or a disaster occurs.

Using today's datastore interfaces, it is difficult if not impossible to handle this wide variety of conditions with a single application. Developers can strive for correct execution most of the time, then have their service fall over during adverse conditions, or they can pick a worst case scenario and build their application to tolerate that, but this can lead to inconsistencies even during normal, good conditions. We can relieve some of this burden by designing type systems and runtime systems for these kinds of applications.

To better handle these constantly changing conditions, we need a better programming model. The high-level goal is to provide ways for programmers to express their performance and correctness requirements in a way that lets the system adapt automatically to changing conditions. This will still require programmers to balance correctness against performance; it is impossible in general to avoid this tradeoff, according to the CAP theorem [@Brewer:CAP;@Gilbert:CAP]. However, we can provide better ways of making these tradeoffs that are more natural for programmers and that can dynamically adapt to conditions.

In this work, we propose a new programming model for distributed datastores that meets the above goals: the *inconsistent, performance-bound, approximate (IPA)* programming model. The IPA model allows programmers to: 

- Specify performance targets so the system can automatically adapt to meet them when conditions change.
- Express where incorrectness is acceptable, to give the system a release valve where it can relax consistency to meet the performance goals.

In return, the system provides *IPA types* that express the consistency and correctness of any potentially inconsistent values, ensuring that programmers handle potential error cases, and allowing applications to make decisions based on the correctness of data. In this paper, we discuss the structure of the type system, how it allows programmers to annotate requirements on *abstract data types (ADTs)*, and how it ensures safety. We also discuss 2 important distributed runtime mechanisms that allow these types to be enforced, including a novel *error tolerance* reservation system. Finally, we demonstrate that these mechanisms allow applications to span the correctness and performance tradeoff with data-structure microbenchmarks and two applications: a simple Twitter clone based on Retwis [@retwis] and a Ticket sales service modelled after FusionTicket [@FusionTicket].
