# Introduction {#sec-intro}

<!-- Imagine a young web app, bright-eyed and ready to face the world with a little local datastore to make sure it doesn't forget a moment of this exciting day. It reaches its thousandth customer and now that local datastore feels a bit cramped, so it swaps in a distributed key/value store that can grow with it. Then one day, it finally gets noticed — featured on TechCrunch and on the top of HackerNews — and suddenly it's inundated with people excited to try it out. The key/value store scales out to handle all the new data and users. But there is a problem: a couple nodes are receiving far more traffic than the rest. It turns out that Barack Obama just joined and everyone wants to see what he's doing. Other hot spots spring up here and there, whenever something important happens in the news or a meme goes viral, and each time the hot nodes get bogged down, latencies spike, and users get frustrated. -->

Imagine you are a young ticket selling app, embarking on a mission to help people everywhere get a seat to watch their favorite shows. Bright-eyed and ready to face the world, you store everything in a key/value store so that you will not forget a moment of this exciting time. It's a distributed key/value store, so when you expand into new cities and reach your millionth customer, your datastore continues to grow with you. You enable strong consistency and use transactions to ensure that no tickets are sold twice or lost, and your customers praise your reliability. "That little app has never steered me wrong", they say.

Then one day, pre-sales for the 7th Star Wars movie come out, almost 40 years after the original, and suddenly you are inundated under a surge over 7 times your usual load, as a record-breaking number of people try to purchase tickets for this one movie. This concentrated traffic causes *hot spots* in your datastore; while most nodes are handling typical traffic, the traffic spike ends up being funneled to a handful of nodes which are responsible for this movie.
These hotspots overload your poor datastore, causing latencies to spike, users' connections to time out, and you have disappointed users who will not get to see the movie on opening night because you were not able to sell them a ticket.
Even major players like Fandango, Regal, and AMC are plagued with service interruptions; some sites even crash or lose data.

This kind of concentrated surge in traffic is a perfect illustration of the contention that occurs all the time in real-world workloads, from ticket sales to social networks.
Power law distributions are everywhere, from popularity of pages to number of followers, leading to network effects which magnify even the slightest signals. Events happening in realtime drive spikes in traffic — sporting events, political events. Taken all together, these effects create memes that propagate like viruses through social media and news sites. Interactivity is crucial to all of this — it both fuels the propagation of memes and directly causes contention.

Paradoxically, though contention is not the average case, it is responsible for many of the most challenging problems: tail latency, failures, and inconsistency bugs.
Most of the time, an application may work correctly, with low latency and no noticeable inconsistency. However, in that 99th percentile case, contention results in a hot spot, where latencies spike, failure rates go up, and in the case of weakly consistent systems, consistency can degrade, exposing bugs or resulting in user-visible inconsistencies.

## Mitigating contention {#sec-hotspot}
Many techniques over many years have tackled this problem from different angles, from research on escrow and fragmenting aggregate fields in the 80s [@ONeil:86], to modern research on compiler-generated coordination based on annotations [@Balegas:15:Indigo;@Sivaramakrishnan:15:Quelea]. Some require a variety of changes to the programming model, while others improve underlying protocols and mechanisms. All are focused on exposing concurrency and making tasks simpler for programmers, but they can be broken down into three broad approaches, shown in [#fig-hotspot].

<!-- This paper will explore the various dimensions upon which these techniques operate to expose concurrency and improve programmability and, using what we have learned from this prior work, propose a way to bring many of the techniques together under one simple and old abstraction: abstract data types. -->

~Fig { #fig-hotspot caption="Overview of approaches for mitigating contention, such as the hotspot in red." }
![](fig/hotspot.pdf)
~

1. Is there any concurrency within the contended record which can be exposed? If operations on the record are commutative, they can safely run concurrently without changing the semantics; *abstract locks* ([#sec-abstract-locks]) leverage this to allow transactions to overlap and avoid false conflicts. *Escrow* ([#sec-escrow]) allows the record to be treated as if it was split into a pool of fragments.

2. If clients are multithreaded, as is the case with frontend web servers that typically handle many end-user requests concurrently, then some of the synchronization work can be offloaded to them. *Combining* ([#sec-combining]) leverages associativity to allow operations to be merged locally and executed as a single operation remotely, reducing the amount of work done on the overloaded datastore. Other techniques like *leases* ([#sec-leases]) let client-side caches avoid costly invalidation messages.

3. If clients are allowed to interact with weakly-synchronized replicas, the load on the contended shard can be reduced. However, this comes at a significant programmability cost: the illusion of a single copy of data is broken and programmers must now reason about replicated state. Weakly synchronized replicas share updates asynchronously, and clients may communicate with multiple replicas, so they can observe effects out of order, or perform updates which conflict and result in inconsistent states.

To be clear, techniques in the first and second categories can be applied to replicated state and maintain strong consistency. Strong consistency requires writes to be linearizable [@Herlihy:90:Linear], which can be accomplished with replication either by funneling through a single master or by a consensus protocol like Paxos [@Lamport:01:Paxos] that makes replicas appear like a single machine. Techniques like E-Paxos [@Moraru:13:EPaxos] would fall under (1) because they expose concurrency while maintaining the single-machine view.

The third category requires much more drastic changes to programming models than the first two because it forces programmers to sacrifice consistency guarantees. However, weak consistency unlocks further improvements to performance properties like availability and lower latency that are impossible with strong consistency. In this work I will focus mostly on techniques that fall into this category because these are the most challenging to understand and require the most significant changes for programmers.

## Balancing requirements {#sec-requirements}
Mitigating contention is just one of the many competing requirements placed on distributed applications. At the minimum, they are expected to be *scalable*, *fault tolerant*, and *highly available* — no matter how many users are active or where they are, they expect to be able to access and get something useful out of the app.

These performance constraints compete with the desire for *programmability* and *correctness*. Fundamentally, strong consistency cannot be provided with high availability — replication must be exposed in some way.
Strict serializability and ACID transactions are among the many useful programming abstractions that must be broken to achieve those performance properties.
Applications are still expected to appear mostly consistent, so developers are forced to think carefully about how to build correct systems with weaker guarantees and choose where to focus their effort.

Luckily, not everything requires the same level of precision or consistency. 
Some actions, such as selling the last ticket to Star Wars' opening night, require precise, consistent execution. Other situations, such as viewing the number of retweets for a popular tweet, do not need to be exactly correct — users may be satisfied as long as the number is the right order of magnitude. Even within the ticket sales example, there is room for relaxation: while there are still thousands of tickets remaining, the exact count shown to users need not be precise, though it ought to be close enough that users can estimate how soon it may sell out. These constraints, both *hard* and *soft*, are typically very difficult or impossible to express in current systems.

At the same time, there are hard and soft constraints on performance. Users demand speedy applications — the common wisdom is that companies lose money for every increase in response latency. Many systems have service-level agreements (SLAs) promising responses within a certain latency for all but the 99th percentile of requests. Throughput during peak times must be able to keep up with the load. Whatever trade offs are made to improve programmability must be balanced against meeting these performance targets, but it is not easy to quantify how changes will affect them.

<!-- Programmers of these distributed applications must constantly juggle these competing hard and soft correctness and performance constraints. There are a huge variety of techniques that have been invented over the years for handling them: new concurrency control schemes, programming models, and data representations, to name a few. Each has its own trade-offs, requiring varying degrees of application changes support them. There ought to be an abstraction that can help programmers make these competing trade-offs and inherit the body of existing optimization techniques. -->

Programmers of these distributed applications must constantly juggle these competing hard and soft correctness and performance constraints.
The plethora of weak consistency models, such as read-your-writes consistency or causal consistency, exist to provide more reasonable programming models for working with replicated state. Yet the massive body of research aimed at reigning in those models attests to the difficulty programmers have in using them.

## Overview

To understand how the various techniques for managing consistency and performance relate to one another, we will explore them in terms of the properties they trade off:

- *Ordering* constraints between operations
- *Visibility:* when and who updates become visible to
- *Uncertainty* about the state in terms of staleness and possible values

We will also discuss how each technique operates, in terms of:

- *Granularity:* Does it affect the whole system, specific records, or specific operations?
- *Knowledge vs control:* Are users granted additional information about performance or consistency or are they given explicit control?

After exploring the space of existing techniques, we will propose a programming model that incorporates these disparate solutions into a single abstraction – using *abstract data types* (ADTs) to concisely describe application semantics and hide the details of the underlying consistency and coordination techniques. Our implementations, in a distributed data analytics system, *Grappa*, and a prototype ADT-store, *Claret*, show significant performance improvements, especially for high contention workloads. In future work, we propose using *inconsistent, probabilistic, and approximate (IPA) types* to trade off precision in order to take advantage of weak consistency and replication for high availability and scalability.

<!-- Our proposed solution to this problem is an old one: *abstract data types* (ADTs). The core idea of ADTs is to present a clear abstract model of some state with operations on it, while hiding all the implementation details. Using ADTs as the building blocks for their applications, programmers can easily reason about their semantics. Distributed systems can take advantage of properties of the ADTs, such as commutativity, to reduce coordination, avoid conflicts, and improve performance. All the details of ordering constraints, visibility, and coordination can be hidden behind the abstraction of data types with well-defined behavior.  -->
