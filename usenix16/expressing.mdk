# Expressing abstract behavior {#sec-expressing}

As in any software design, building Claret applications involves choosing the right data structures. There are many valid ways to compose ADTs to model application data, but to achieve the best performance, one should express as much high-level abstract behavior as possible through ADT operations.

Typically, the more specialized an ADT is, the more concurrency it can expose, so finding the closest match is essential.
For example, one could use a counter to generate unique identifiers, but counters must return numbers in sequence, which is difficult to scale (as implementers of TPC-C [@TPCC], which explicitly requires this, know well). A special `UniqueID` type succinctly communicates that non-sequential IDs are acceptable, allowing a commutative implementation.

Claret has a library of pre-defined ADTs ([#tab-adt-list]) used to implement the applications in this paper.
Reusing existing ADTs saves implementation time and effort, but may not always expose the maximum amount of concurrency.
Custom ADTs can express more complex application-specific properties, but the developer is responsible for specifying the abstract behavior for Claret.
[todo: example: bank account adt? (not one of our apps, but there is an easy-to-describe custom adt there)]
The next sections will show how ADT behavior is specified in Claret to expose abstract properties of ADTs for our optimizations to leverage.

~ Tab { #tab-adt-list caption="Library of built-in data types."}
| Data type      | Description                               |
|:---------------|:-{width=2.08in}---------------------------|
| `UIdGenerator` | Create unique identifiers (not            |
|                | necessarily sequential) (`next`)          |
|----------------|-------------------------------------------|
| `Dict`         | Map (or "hash") which allows setting      |
|                | or getting multiple fields atomically     |
|----------------|-------------------------------------------|
| `ScoredSet`    | Set with unique items ranked by an        |
|                | associated score (`add`, `size`, `range`) |
|----------------|-------------------------------------------|
| `TopK`         | Like `ScoredSet` but keeps only           |
|                | highest-ranked items (`add`, `max`, ...)  |
|----------------|-------------------------------------------|
| `SummaryBag`   | Container where only summary stats        |
|                | of added items can be retrieved           |
|                | (`add`, `mean`, `max`)                    |
|----------------|-------------------------------------------|
~

## Commutativity Specification {#sec-commutativity-spec}

~ Tab { #tab-spec caption="Abstract Commutativity Specification for Set." }
| Method:            | And:           | Commute when:               |
|:-------------------|:---------------|:----------------------------|
|`add(x): void`      | `add(y)`       | $\forall x, y$              |
|--------------------|----------------|-----------------------------|
|`remove(x): void`   | `remove(y)`    | $\forall x, y$              |
|                    | `add(y)`       | $x \ne y$                   |
|--------------------|----------------|-----------------------------|
|`size(): int`       | `add(x)`       | $x \in Set$                 |
|                    | `remove(x)`    | $x \notin Set$              |
|--------------------|----------------|-----------------------------|
|`contains(x): bool` | `add(y)`       | $x \ne y \lor y \in Set$    |
|                    | `remove(y)`    | $x \ne y \lor y \notin Set$ |
|                    | `size()`       | $\forall x$                 |
|--------------------|----------------|-----------------------------|
~

*Commutativity* is not a property of an operation in isolation.
A *pair* of operations commute if executing them on their target record in either order will produce the same outcome. Using the definitions from [@Kulkarni:PLDI11], whether or not a pair of method invocations commute is a function of the methods, their arguments, their return values, and the *abstract state* of their target. We call the full set of commutativity rules for an ADT its *commutativity specification.* An example specification for a *Set* is shown in [#tab-spec]. <!-- There are actually many valid specifications which expose less than the maximum commutativity but may be cheaper to implement. -->
However, we need something besides this declarative representation to communicate this specification to Claret's concurrency controller.

### Abstract lock interface

~ Listing { #lock-interface caption="Interface for expressing commutativity for a data type. Typical implementations use *modes* to easily determine sets of allowed operations, and a *set* of lock-holders to keep track of outstanding operations." }
![Abstract lock interface](fig/abstract-lock.pdf){.onecol}
~

In Claret, each data type describes its commutativity by implementing the *abstract lock* interface shown in [#lock-interface]. This imperative interface allows data types to be arbitrarily introspective when determining commutativity. In our implementation, clients must acquire locks for each operation before executing them. When the datastore receives a lock request for an operation on a record, the concurrency controller queries the abstract lock associated with the record using its `acquire` method, which checks the new operation against the other operations currently holding the lock to determine if it can execute concurrently (commutes) with all of them.

Implementations of this interface typically keep a set of the current lock-holders. They determine which operations are currently permitted to share the lock by dividing them into *modes*. For example, reader/writer locks have a *read* mode for all read-only operations and an *exclusive* mode for the rest, while abstract locks have additional modes, such as an *append* mode for sets which allows all `add`s. More fine-grained tracking in `acquire` can expose more concurrency; for instance, `contains` can execute during *append* if the item already exists.

### Phaser interface { #sec-phaser }

~ Listing { #lst-phaser caption="Phaser interface (example implementation): `enqueue` is called after an operation fails to acquire a lock, `signal` is called when a phase finishes (all ops in the phase commit and release the lock)." }
![Phaser interface](fig/phaser.pdf){.onecol}
~

Phasing requires knowing how to divide operations into *phases*, similar to the *modes* for locks, but rather than tracking which operations currently hold the lock, the *phaser* associated with a record tracks all the operations waiting to acquire the lock. When an operation fails to acquire the lock, the controller *enqueues* it with the phaser. When a phase completes, the abstract lock *signals* the phaser, requesting operations for a new phase.

The simplest implementations keep queues corresponding to each mode. [#lst-phaser], for example, shows `adders`, which will contain all operations that may insert into the set (just `add`), and `readers`, which includes any read-only operations (`size`, `contains`, `range`, etc).
As with abstract locks, more complicated phaser implementations can allow operations to be in multiple modes or use more complex state-dependent logic to determine which operations to signal.

## Combiners

~ Fig { #fig-combining caption="Combining `range` operations: the second operation's result can be computed locally because its range is a subset of the first, so the two can be combined." }
![Combiner for range](fig/combiner.pdf){.onecol}
~

Finally, ADTs wishing to perform combining ([#sec-combining]) must implement a *combiner* to tell Claret how to combine operations.
Combiners only have one method, `combine`, which attempts to match the provided operation against any other outstanding operations (operations that have acquired a lock but not committed yet).

Remember from [#sec-transactions] that operations are split into *execute* and *commit*. Combining is only concerned with the *execute* part of the operation. Operations that do not return a value (such as `add`) are simple to combine: any commuting operations essentially share the acquired lock and commit together. Operations that return a value in *execute* (any read), can only be combined if they can share the result. For `zset.size`, all concurrent transactions should read the same size, so combined `size` ops can all return the size retrieved by the first one. [#fig-combining] illustrates a more complex example of combining two `range` operations on a `zset`. They can be combined because the second requests a sub-range of the first, so the combiner can produce the result.

To avoid excessive matching, only operations declared *combinable* are compared. The client-side library keeps track of outstanding combinable operations with a map of combiners indexed by key. Combiners are registered after a lock is acquired and removed when the operation commits. Before sending an acquire request for a combinable operation, the client checks the map for that key. If none is found, or the combine fails, it is sent to the server as usual. If it succeeds, the result is returned immediately, and Claret handles merging the two transactions as described before in [#sec-combining].

## Adding a custom ADT
The ADTs provided by Claret are all implemented using these interfaces to communicate their commutativity and associativity to Claret's concurrency control system. To implement a custom ADT that can take advantage of all of the optimizations, programmers must simply implement an abstract lock, phaser, and combiner. 
ADT designers could choose to use simple implementations similar to those in Claret that just divide operations statically into modes, or experts could use more state-dependent logic to provide fine-grained concurrency if needed.
